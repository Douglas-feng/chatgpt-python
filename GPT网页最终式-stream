from flask import Flask, render_template, request, stream_with_context, Response, jsonify
import openai
import random

# 设置代理网址
openai.api_base = "https://api.openai-proxy.com/v1"

# 替换为您自己的OpenAI API密钥列表
api_keys = [
    "",
]
# 创建Flask应用程序
app = Flask(__name__)
# 定义可供选择的模型
available_models = {
    "gpt-3.5-turbo": "GPT-3.5-Turbo(4097tokens)",
    "gpt-3.5-turbo-16k": "GPT-3.5-Turbo-16k(16385tokens)",
    "gpt-3.5-turbo-0613": "GPT-3.5-Turbo-0613(4097tokens)",
    "gpt-3.5-turbo-16k-0613": "GPT-3.5-Turbo-16k-0613(16385tokens)",
    "gpt-3.5-turbo-0301": "GPT-3.5-Turbo-0301(4097tokens)",
    "gpt-4": "GPT-4(8192tokens)",
    "gpt-4-0613": "GPT-4-0613(8192tokens)",
    "gpt-4-32k": "GPT-4-32k(32768tokens)",
    "gpt-4-32k-0613": "GPT-4-32k-0613(32768tokens)",
    "gpt-4-0314": "GPT-4-0314(8192tokens)",
    "gpt-4-32k-0314": "GPT-4-32k-0314(32768tokens)"
}
messages = []

@app.route('/')
def index():
    return render_template('7.html', models=available_models)

@app.route('/get_response', methods=['POST'])
def get_response():
    user_input = request.json.get('user_input')
    selected_model = request.json.get('selected_model')
    system_message = request.json.get('system_message')
    temperature = float(request.json.get('temperature'))
    max_tokens = int(request.json.get('max_tokens'))
    continuous_chat = request.json.get('continuous_chat')
    print("用户输入内容：", user_input)

    if continuous_chat == "false":
        messages.clear()  # 只有在禁用连续对话时清空消息列表
        messages.append({"role": "system", "content": system_message})
        messages.append({"role": "user", "content": user_input})
    else:
        messages.append({"role": "user", "content": user_input})
    selected_api_key = random.choice(api_keys)
    openai.api_key = selected_api_key.strip()
    print(openai.api_key)

    if len(messages) > 2:
        messages.pop(0)

    response = openai.ChatCompletion.create(
        model=selected_model,
        messages=messages,
        temperature=temperature,
        max_tokens=max_tokens,
        stream=True
    )

    def get_stream(tar_get_response):
        for chunk in tar_get_response:
            chunk_message = chunk['choices'][0]['delta']
            print(chunk_message)
            if chunk_message != "":
                try:
                    content = chunk_message["content"]
                    for line in content.split("\n"):
                        messages.append({"role": "assistant", "content": line})
                        yield line
                        print("GPT回复内容：", line)
                except:
                    yield "\n"
    response = Response(get_stream(response),content_type='text/html')
    return response

# @app.route('/clear_user',method=['POST'])
# def clear_information():



if __name__ == '__main__':
    app.run('0.0.0.0', 80)
